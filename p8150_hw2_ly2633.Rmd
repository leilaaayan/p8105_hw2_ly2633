---
title: "p8105_hw2_ly2633"
author: "Leila Yan"
date: "2024-09-25"
output: github_document
---

```{r setup}
library(tidyverse)
```
## Problem 1
Read in the dataset
```{r}
transit_df = 
  read_csv("Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = case_match(entry, 
                            "YES" ~ TRUE,
                            "NO" ~ FALSE))
```
Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy? 

Answers:
The dataset contains information about the entrances and exits of subway stations in New York City. It includes several key variables: line, which identifies the subway line associated with each entrance or exit, and station_name, which provides the name of the station. The geographical coordinates of each station are given by station_latitude and station_longitude. The dataset also has columns for route1 through route11, which indicate the subway routes available at each station. entrance_type describes the type of entrance, such as stair, elevator, door, escalator, etc, while entry indicates whether entry is allowed at the specified location (TRUE/FALSE). The vending column shows whether there are vending machines available for purchasing tickets, and ada is a boolean variable indicating whether the entrance or exit is compliant with the Americans with Disabilities Act (ADA). This dataset contains 1868 entries and 32 columns (1868 x 32). Yes, the data is tidy after I performed the data cleaning steps, such as clean_names(). 

The data cleaning process began by loading the dataset from a CSV file. Next, janitor::clean_names() was used to standardize column names, converting them to lowercase and snake_case for easier reference. After that, specific columns were selected, including those from line through entry, as well as vending and ada, which were deemed most relevant for the analysis. Finally, the entry column was modified using case_match() to convert the original values of "YES" and "NO" into logical values (TRUE and FALSE), making the data easier to work with.


How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here. How many stations are ADA compliant? What proportion of station entrances / exits without vending allow entrance?
```{r}
#distinct stations
distinct_stations = 
  transit_df %>%
  distinct(line, station_name) %>%
  nrow()

distinct_stations

#ada compliance
ada_compliant_stations =
  transit_df %>%
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>%
  nrow()

ada_compliant_stations

#proportion of station/entrances/exits without vending allow entrance
without_vending_entry = 
  transit_df %>%
  filter(vending == "NO", entry == TRUE) %>%
  nrow()

total_without_vending =
  transit_df %>%
  filter(vending == "NO") %>%
  nrow()

proportion_without_vending_entry <- without_vending_entry / total_without_vending

proportion_without_vending_entry
```
Answers:
The dataset contains a total of 465 distinct subway stations in New York City, where stations are identified by both name and line. Out of these stations, 84 are compliant with ADA. Additionally, around 37.7% of station entrances or exits that do not have vending machines still allow entry. These metrics provide insights into the accessibility and functionality of the NYC subway system.


Reformat data so that route number and route name are distinct variables. 
```{r}
transit_df_long=
  transit_df %>%
  mutate(across(starts_with("route"), as.character)) %>%
  pivot_longer(
    route1:route11, 
    names_to = "route_number", 
    values_to = "route_name", 
    values_drop_na = TRUE
    )
```

How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?
```{r}
stations_A_train =
  transit_df_long %>%
  filter(route_name == "A")


distinct_stations_A_train =
  stations_A_train %>%
  distinct(station_name) %>%
  nrow()

distinct_stations_A_train

ada_compliant_stations_A_train =
  stations_A_train %>%
  filter(ada == TRUE) %>%   # Filter for ADA compliant stations
  distinct(station_name) %>%  # Get distinct station names
  nrow()

ada_compliant_stations_A_train
```
Answers:
56 distinct stations serve the A train. Of the stations that serve the A train, 16 stations are ADA compliant.



## Problem 2

Read and clean the Mr. Trash Wheel sheet:
- specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
library(readxl)
mr_trash_wheel_df =
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%  # Omit rows where the 'dumpster' column is NA
  select(where(~ !all(is.na(.)))) %>% # omit non-data entries
  mutate(sports_balls = as.integer(round(sports_balls)))

```

Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.

```{r}
prof_trash_wheel_df =
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster))

gwynnda_trash_wheel_df =
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster))

# convert year column to character for consistency
gwynnda_trash_wheel_df <- gwynnda_trash_wheel_df %>%
  mutate(year = as.character(year))

prof_trash_wheel_df <- prof_trash_wheel_df %>%
  mutate(year = as.character(year))

mr_trash_wheel_df <- mr_trash_wheel_df %>%
  mutate(year = as.character(year))

# Now combine the datasets
combined_trash_wheel_df <- bind_rows(
  gwynnda_trash_wheel_df,
  prof_trash_wheel_df,
  mr_trash_wheel_df
)

```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?

```{r}
#total weight of trash collected by Professor Trash Wheel
total_weight =
  prof_trash_wheel_df %>%
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE))

print(total_weight)

total_cigarette_butts =
  gwynnda_trash_wheel_df %>%
  filter(month == "June", year == 2022) %>%  # Filter for June 2022
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))  # Sum the cigarette butts

print(total_cigarette_butts)
```
The total weight of trash collected by Professor Trash Wheel is 216.26 tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is 18120. The combined dataset, combined_trash_wheel_df, contains 845 observations from three different trash wheel datasets (gwynnda_trash_wheel_df, prof_trash_wheel_df, and mr_trash_wheel_df). Each observation represents a collection event over various dates, capturing data such as the number of plastic bottles, polystyrene, and cigarette butts collected, as well as the weight and volume of trash in each dumpster. Key variables include dumpster, which identifies collection events, and temporal variables like month, year, and date. Waste metrics include weight_tons and volume_cubic_yards, providing measures of the collected trash volume. The dataset also tracks specific types of waste, such as plastic_bottles, polystyrene, and cigarette_butts. Additionally, some columns, such as glass_bottles, homes_powered, and sports_balls, contain NA values, indicating that these measurements were not consistently recorded across all trash wheels. This comprehensive dataset is valuable for analyzing temporal and spatial trends in waste collection, understanding the environmental impact, and informing waste management strategies. Insights derived from this data can support targeted interventions to reduce specific types of waste, like plastic or cigarette butts, and provide a broader understanding of changes in waste generation patterns over time.

## Problem 3
Read in datasets, clean, and tidy
```{r}
# remove bakers' last name and convert baker_name to baker
bakers_df = 
   read_csv("gbb_datasets/bakers.csv") %>%
  janitor::clean_names() %>%
  mutate(baker = sub(" .*", "", baker_name)) %>% 
  select(-baker_name)

bakes_df = 
   read_csv("gbb_datasets/bakes.csv") %>%
  janitor::clean_names()

results_df = 
   read_csv("gbb_datasets/results.csv", skip=2) %>%
  janitor::clean_names() 
```

check for completeness
```{r}
anti_join(bakes_df, bakers_df, results_df, by = "baker")
```

Merge datasets into one
```{r}
mergeingtwo_df = 
  left_join(bakers_df, bakes_df, by = "baker")

bakingmerged_df = 
  left_join(mergeingtwo_df, results_df, by = "baker") %>%
  arrange(series) %>%
  relocate(series)

#?????? two episode columns and three series columns
```
Export the result as a CSV in the directory containing the original datasets.
```{r}
write_csv(bakingmerged_df, "gbb_datasets/bakingmerged_df.csv")
```

Describe your data cleaning process, including any questions you have or choices you made. Briefly discuss the final dataset.

Answers:


Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?

???? how do I create a table

```{r}
library(knitr)

star_bakers =
  bakingmerged_df %>%
  filter(result == "STAR BAKER" | result == "WINNER") %>%
  select(series, episode.x, baker, result) %>%
  filter(series >= 5 & series <= 10) %>% 
  arrange(series, episode.x) %>%
  kable(col.names = c("series", "episode.x", "baker", "result"))
```
Answers:




Import, clean, tidy, and organize the viewership data in viewership.csv. Show the first 10 rows of this dataset. 
```{r}
viewers_df = 
   read_csv("gbb_datasets/viewers.csv") %>%
  janitor::clean_names() 

head(viewers_df, 10)
```
What was the average viewership in Season 1? In Season 5?
```{r}
viewers_df %>%
  summarize(average_viewership_1 = mean(series_1, na.rm = TRUE))

viewers_df %>%
  summarize(average_viewership_5 = mean(series_5, na.rm = TRUE))
```
Answers:
The average viewership in season 1 is 2.77 and that in season 5 is 10.0393.
